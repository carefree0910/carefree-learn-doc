(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{83:function(e,n,t){"use strict";t.r(n),t.d(n,"frontMatter",(function(){return c})),t.d(n,"metadata",(function(){return o})),t.d(n,"rightToc",(function(){return s})),t.d(n,"default",(function(){return p}));var a=t(3),r=t(7),i=(t(0),t(97)),c={id:"MNIST",title:"MNIST"},o={unversionedId:"examples/MNIST",id:"examples/MNIST",isDocsHomePage:!1,title:"MNIST",description:"The MNIST dataset is a dataset of handwritten digits that is commonly used as the 'Hello World' dataset in Deep Learning domain. It contains 60,000 training images and 10,000 testing images, and",source:"@site/docs/examples/mnist.md",slug:"/examples/MNIST",permalink:"/carefree-learn-doc/docs/examples/MNIST",version:"current",lastUpdatedAt:1635039016,sidebar:"docs",previous:{title:"Titanic",permalink:"/carefree-learn-doc/docs/examples/Titanic"},next:{title:"General",permalink:"/carefree-learn-doc/docs/user-guides/general"}},s=[{value:"Classification",id:"classification",children:[]}],l={rightToc:s};function p(e){var n=e.components,t=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(a.a)({},l,t,{components:n,mdxType:"MDXLayout"}),Object(i.b)("p",null,"The MNIST dataset is a dataset of handwritten digits that is commonly used as the 'Hello World' dataset in Deep Learning domain. It contains 60,000 training images and 10,000 testing images, and\n",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," provided a straightforward API to access it."),Object(i.b)("p",null,"MNIST dataset can be used for training various image processing systems. In this article, we will demonstrate how to actually utilize ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," to solve these different tasks on MNIST dataset."),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'# preparations\n\nimport torch\nimport cflearn\n\nimport numpy as np\nimport torch.nn as nn\n\n# MNIST dataset could be prepared with this one line of code\ndata = cflearn.cv.MNISTData(batch_size=16, transform="to_tensor")\n\n# for reproduction\nnp.random.seed(142857)\ntorch.manual_seed(142857)\n')),Object(i.b)("div",{className:"admonition admonition-tip alert alert--success"},Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(i.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"}),Object(i.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"})))),"tip")),Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(i.b)("ul",{parentName:"div"},Object(i.b)("li",{parentName:"ul"},"As shown above, the MNIST dataset could be easily turned into a ",Object(i.b)("inlineCode",{parentName:"li"},"DLDataModule")," instance, which is the common data interface used in ",Object(i.b)("inlineCode",{parentName:"li"},"carefree-learn"),"."),Object(i.b)("li",{parentName:"ul"},"The ",Object(i.b)("inlineCode",{parentName:"li"},"transform")," argument specifies which transform do we want to use to pre-process the input batch. See ",Object(i.b)("a",Object(a.a)({parentName:"li"},{href:"/docs/user-guides/computer-vision#transforms"}),"Transforms")," section for more details.")))),Object(i.b)("h2",{id:"classification"},"Classification"),Object(i.b)("table",null,Object(i.b)("thead",{parentName:"table"},Object(i.b)("tr",{parentName:"thead"},Object(i.b)("th",Object(a.a)({parentName:"tr"},{align:"center"}),"Python source code"),Object(i.b)("th",Object(a.a)({parentName:"tr"},{align:"center"}),"Jupyter Notebook"),Object(i.b)("th",Object(a.a)({parentName:"tr"},{align:"center"}),"Task"))),Object(i.b)("tbody",{parentName:"table"},Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),Object(i.b)("a",Object(a.a)({parentName:"td"},{href:"https://github.com/carefree0910/carefree-learn/blob/dev/examples/cv/mnist/run_clf.py"}),"run_clf.py")),Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),Object(i.b)("a",Object(a.a)({parentName:"td"},{href:"https://nbviewer.jupyter.org/github/carefree0910/carefree-learn/blob/dev/examples/cv/mnist/clf.ipynb"}),"clf.ipynb")),Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:"center"}),"Computer Vision \ud83d\uddbc\ufe0f")))),Object(i.b)("p",null,"For demo purpose, we are going to build a simple convolution-based classifier:"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'@cflearn.register_module("simple_conv")\nclass SimpleConvClassifier(nn.Sequential):\n    def __init__(self, in_channels: int, num_classes: int):\n        super().__init__(\n            nn.Conv2d(in_channels, 16, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(16),\n            nn.MaxPool2d(2),\n            nn.Conv2d(16, 32, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(32),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(1),\n            nn.Linear(128, num_classes),\n        )\n')),Object(i.b)("p",null,"We leveraged the ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"/docs/developer-guides/computer-vision-customization#customize-models"}),Object(i.b)("inlineCode",{parentName:"a"},"register_module"))," API here, which can turn a general ",Object(i.b)("inlineCode",{parentName:"p"},"nn.Module")," instance to a ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"/docs/design-principles/#model"}),Object(i.b)("inlineCode",{parentName:"a"},"ModelProtocol"))," in ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn"),". After registered, it can be easily accessed with its name (",Object(i.b)("inlineCode",{parentName:"p"},'"simple_conv"'),"):"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'cflearn.api.fit_cv(\n    data,\n    "simple_conv",\n    {"in_channels": 1, "num_classes": 10},\n    loss_name="cross_entropy",\n    metric_names="acc",\n    fixed_epoch=1,                                  # for demo purpose, we only train our model for 1 epoch\n    cuda=0 if torch.cuda.is_available() else None,  # use CUDA if possible\n)\n')),Object(i.b)("p",null,"Our model achieves 98.0400% accuracy on validation set within 1 epoch, not bad!"))}p.isMDXComponent=!0},97:function(e,n,t){"use strict";t.d(n,"a",(function(){return d})),t.d(n,"b",(function(){return u}));var a=t(0),r=t.n(a);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function c(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?c(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):c(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=r.a.createContext({}),p=function(e){var n=r.a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},d=function(e){var n=p(e.components);return r.a.createElement(l.Provider,{value:n},e.children)},b={inlineCode:"code",wrapper:function(e){var n=e.children;return r.a.createElement(r.a.Fragment,{},n)}},m=r.a.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),d=p(t),m=a,u=d["".concat(c,".").concat(m)]||d[m]||b[m]||i;return t?r.a.createElement(u,o(o({ref:n},l),{},{components:t})):r.a.createElement(u,o({ref:n},l))}));function u(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,c=new Array(i);c[0]=m;var o={};for(var s in n)hasOwnProperty.call(n,s)&&(o[s]=n[s]);o.originalType=e,o.mdxType="string"==typeof e?e:a,c[1]=o;for(var l=2;l<i;l++)c[l]=t[l];return r.a.createElement.apply(null,c)}return r.a.createElement.apply(null,t)}m.displayName="MDXCreateElement"}}]);