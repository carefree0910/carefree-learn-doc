(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{106:function(e,n,t){"use strict";t.d(n,"a",(function(){return p})),t.d(n,"b",(function(){return u}));var a=t(0),r=t.n(a);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function c(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?c(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):c(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=r.a.createContext({}),b=function(e){var n=r.a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},p=function(e){var n=b(e.components);return r.a.createElement(s.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.a.createElement(r.a.Fragment,{},n)}},d=r.a.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),p=b(t),d=a,u=p["".concat(c,".").concat(d)]||p[d]||m[d]||i;return t?r.a.createElement(u,o(o({ref:n},s),{},{components:t})):r.a.createElement(u,o({ref:n},s))}));function u(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,c=new Array(i);c[0]=d;var o={};for(var l in n)hasOwnProperty.call(n,l)&&(o[l]=n[l]);o.originalType=e,o.mdxType="string"==typeof e?e:a,c[1]=o;for(var s=2;s<i;s++)c[s]=t[s];return r.a.createElement.apply(null,c)}return r.a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},96:function(e,n,t){"use strict";t.r(n),t.d(n,"frontMatter",(function(){return c})),t.d(n,"metadata",(function(){return o})),t.d(n,"rightToc",(function(){return l})),t.d(n,"default",(function(){return b}));var a=t(3),r=t(7),i=(t(0),t(106)),c={id:"distributed",title:"Distributed"},o={unversionedId:"user-guides/distributed",id:"user-guides/distributed",isDocsHomePage:!1,title:"Distributed",description:"Distributed Training",source:"@site/docs/user-guides/distributed.md",slug:"/user-guides/distributed",permalink:"/carefree-learn-doc/docs/user-guides/distributed",version:"current",lastUpdatedAt:1606302561,sidebar:"docs",previous:{title:"AutoML",permalink:"/carefree-learn-doc/docs/user-guides/auto-ml"},next:{title:"Production",permalink:"/carefree-learn-doc/docs/user-guides/production"}},l=[{value:"Distributed Training",id:"distributed-training",children:[]},{value:"Benchmarking",id:"benchmarking",children:[]},{value:"Hyper Parameter Optimization (HPO)",id:"hyper-parameter-optimization-hpo",children:[]}],s={rightToc:l};function b(e){var n=e.components,t=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(a.a)({},s,t,{components:n,mdxType:"MDXLayout"}),Object(i.b)("h2",{id:"distributed-training"},"Distributed Training"),Object(i.b)("p",null,"In ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn"),", ",Object(i.b)("strong",{parentName:"p"},"Distributed Training")," doesn't mean training your model on multiple GPUs or multiple machines, because ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," focuses on tabular datasets (or, structured datasets) which are often not as large as unstructured datasets. Instead, ",Object(i.b)("strong",{parentName:"p"},"Distributed Training")," in ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," means ",Object(i.b)("strong",{parentName:"p"},"training multiple models")," at the same time. This is important because:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Deep Learning models suffer from randomness, so we need to train multiple models with the same algorithm and calculate the mean / std of the performances to evaluate the algorithm's capacity and stability."),Object(i.b)("li",{parentName:"ul"},"Ensemble these models (which are trained with the same algorithm) can boost the algorithm's performance without making any changes to the algorithm itself."),Object(i.b)("li",{parentName:"ul"},"Parameter searching will be easier & faster.")),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'import cflearn\nfrom cfdata.tabular import TabularDataset\n\nif __name__ == \'__main__\':\n    x, y = TabularDataset.iris().xy\n    # Notice that 3 fcnn were trained simultaneously with this line of code\n    results = cflearn.repeat_with(x, y, num_repeat=3, num_jobs=0)\n    patterns = results.patterns["fcnn"]\n    # And it is fairly straight forward to apply stacking ensemble\n    ensemble = cflearn.Ensemble.stacking(patterns)\n    patterns_dict = {"fcnn_3": patterns, "fcnn_3_ensemble": ensemble}\n    cflearn.evaluate(x, y, metrics=["acc", "auc"], other_patterns=patterns_dict)\n')),Object(i.b)("div",{className:"admonition admonition-note alert alert--secondary"},Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(i.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(i.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"})))),"note")),Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(i.b)("p",{parentName:"div"},"It is necessary to wrap codes under ",Object(i.b)("inlineCode",{parentName:"p"},"__main__")," on WINDOWS when running distributed codes."))),Object(i.b)("p",null,"Which yields:"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-text"}),"================================================================================================================================\n|        metrics         |                       acc                        |                       auc                        |\n--------------------------------------------------------------------------------------------------------------------------------\n|                        |      mean      |      std       |     score      |      mean      |      std       |     score      |\n--------------------------------------------------------------------------------------------------------------------------------\n|         fcnn_3         |    0.937778    |    0.017498    |    0.920280    | -- 0.993911 -- |    0.000274    |    0.993637    |\n--------------------------------------------------------------------------------------------------------------------------------\n|    fcnn_3_ensemble     | -- 0.953333 -- | -- 0.000000 -- | -- 0.953333 -- |    0.993867    | -- 0.000000 -- | -- 0.993867 -- |\n================================================================================================================================\n")),Object(i.b)("div",{className:"admonition admonition-info alert alert--info"},Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(i.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(i.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"info")),Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(i.b)("p",{parentName:"div"},"You might notice that the best results of each column is highlighted with a pair of '--'."))),Object(i.b)("h2",{id:"benchmarking"},"Benchmarking"),Object(i.b)("p",null,Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," has a related repository (namely ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"https://github.com/carefree0910/carefree-learn-benchmark"}),Object(i.b)("inlineCode",{parentName:"a"},"carefree-learn-benchmark")),") which implemented some sophisticated benchmarking functionalities. However, for many common use cases, ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," provides ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"apis#repeat_with"}),Object(i.b)("inlineCode",{parentName:"a"},"cflearn.repeat_with"))," and ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"apis#evaluate"}),Object(i.b)("inlineCode",{parentName:"a"},"cflearn.evaluate"))," for quick benchmarking. For example, if we want to compare the ",Object(i.b)("inlineCode",{parentName:"p"},"linear")," model and the ",Object(i.b)("inlineCode",{parentName:"p"},"fcnn")," model by running them ",Object(i.b)("inlineCode",{parentName:"p"},"3")," times, we can simply:"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'import cflearn\nimport numpy as np\n\nx = np.random.random([1000, 10])\ny = np.random.random([1000, 1])\nresult = cflearn.repeat_with(x, y, models=["linear", "fcnn"], num_repeat=3)\ncflearn.evaluate(x, y, pipelines=result.pipelines)\n')),Object(i.b)("p",null,"Which yields"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-text"}),"================================================================================================================================\n|        metrics         |                       mae                        |                       mse                        |\n--------------------------------------------------------------------------------------------------------------------------------\n|                        |      mean      |      std       |     score      |      mean      |      std       |     score      |\n--------------------------------------------------------------------------------------------------------------------------------\n|          fcnn          | -- 0.251717 -- | -- 0.002158 -- | -- -0.25387 -- | -- 0.086110 -- | -- 0.002165 -- | -- -0.08827 -- |\n--------------------------------------------------------------------------------------------------------------------------------\n|         linear         |    0.283154    |    0.015341    |    -0.29849    |    0.118122    |    0.016185    |    -0.13430    |\n================================================================================================================================\n")),Object(i.b)("p",null,"We can also leverage distributed training supported in ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," for faster benchmarking by specifying ",Object(i.b)("inlineCode",{parentName:"p"},"num_jobs")," to a higher value:"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'if __name__ == "__main__":\n    result = cflearn.repeat_with(x, y, models=["linear", "fcnn"], num_repeat=3, num_jobs=2)\n    cflearn.evaluate(x, y, pipelines=result.pipelines)\n')),Object(i.b)("div",{className:"admonition admonition-caution alert alert--warning"},Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(i.b)("h5",{parentName:"div"},Object(i.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(i.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"16",height:"16",viewBox:"0 0 16 16"}),Object(i.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"})))),"caution")),Object(i.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(i.b)("p",{parentName:"div"},"It is not recommended to enable distributed training unless:"),Object(i.b)("ul",{parentName:"div"},Object(i.b)("li",{parentName:"ul"},"There are plenty of tasks that we need to run. "),Object(i.b)("li",{parentName:"ul"},"Running each task is quite costly in time."),Object(i.b)("li",{parentName:"ul"},Object(i.b)("inlineCode",{parentName:"li"},"num_jobs")," could be set to a relatively high value (e.g., ",Object(i.b)("inlineCode",{parentName:"li"},"8"),").")),Object(i.b)("p",{parentName:"div"},"Otherwise the overhead brought by launching distributed training might actually hurt the overall performance."),Object(i.b)("p",{parentName:"div"},"However, there are no 'golden rules' of whether we should use distributed training or not for us to follow, so the best practice is to actually try it out in a smaller scale \ud83e\udd23"))),Object(i.b)("h2",{id:"hyper-parameter-optimization-hpo"},"Hyper Parameter Optimization (HPO)"),Object(i.b)("p",null,"Although ",Object(i.b)("inlineCode",{parentName:"p"},"carefree-learn")," has already provided an ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"auto-ml"}),Object(i.b)("inlineCode",{parentName:"a"},"AutoML"))," API, we can still play with the ",Object(i.b)("strong",{parentName:"p"},"HPO")," APIs manually:"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),"import cflearn\nfrom cfdata.tabular import TabularDataset\n \nif __name__ == '__main__':\n    x, y = TabularDataset.iris().xy\n    # Bayesian Optimization (BO) will be used as default\n    hpo = cflearn.tune_with(\n        x, y,\n        task_type=\"clf\",\n        num_repeat=2, num_parallel=0, num_search=10\n    )\n    # We can further train our model with the best hyper-parameters we've obtained:\n    m = cflearn.make(**hpo.best_param).fit(x, y)\n    cflearn.evaluate(x, y, pipelines=m)\n")),Object(i.b)("p",null,"Then you will see something like this:"),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-text"}),"~~~  [ info ] Results\n================================================================================================================================\n|        metrics         |                       acc                        |                       auc                        |\n--------------------------------------------------------------------------------------------------------------------------------\n|                        |      mean      |      std       |     score      |      mean      |      std       |     score      |\n--------------------------------------------------------------------------------------------------------------------------------\n|        0659e09f        |    0.943333    |    0.016667    |    0.926667    |    0.995500    |    0.001967    |    0.993533    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        08a0a030        |    0.796667    |    0.130000    |    0.666667    |    0.969333    |    0.012000    |    0.957333    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        1962285c        |    0.950000    |    0.003333    |    0.946667    |    0.997467    |    0.000533    |    0.996933    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        1eb7f2a0        |    0.933333    |    0.020000    |    0.913333    |    0.994833    |    0.003033    |    0.991800    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        4ed5bb3b        |    0.973333    |    0.013333    |    0.960000    |    0.998733    |    0.000467    |    0.998267    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        5a652f3c        |    0.953333    | -- 0.000000 -- |    0.953333    |    0.997400    |    0.000133    |    0.997267    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        82c35e77        |    0.940000    |    0.020000    |    0.920000    |    0.995467    |    0.002133    |    0.993333    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        a9ef52d0        | -- 0.986667 -- |    0.006667    | -- 0.980000 -- | -- 0.999200 -- | -- 0.000000 -- | -- 0.999200 -- |\n--------------------------------------------------------------------------------------------------------------------------------\n|        ba2e179a        |    0.946667    |    0.026667    |    0.920000    |    0.995633    |    0.001900    |    0.993733    |\n--------------------------------------------------------------------------------------------------------------------------------\n|        ec8c0837        |    0.973333    | -- 0.000000 -- |    0.973333    |    0.998867    |    0.000067    |    0.998800    |\n================================================================================================================================\n\n~~~  [ info ] Best Parameters\n----------------------------------------------------------------------------------------------------\nacc  (a9ef52d0) (0.986667 \xb1 0.006667)\n----------------------------------------------------------------------------------------------------\n{'optimizer': 'rmsprop', 'optimizer_config': {'lr': 0.005810863965757382}}\n----------------------------------------------------------------------------------------------------\nauc  (a9ef52d0) (0.999200 \xb1 0.000000)\n----------------------------------------------------------------------------------------------------\n{'optimizer': 'rmsprop', 'optimizer_config': {'lr': 0.005810863965757382}}\n----------------------------------------------------------------------------------------------------\nbest (a9ef52d0)\n----------------------------------------------------------------------------------------------------\n{'optimizer': 'rmsprop', 'optimizer_config': {'lr': 0.005810863965757382}}\n----------------------------------------------------------------------------------------------------\n\n~~  [ info ] Results\n================================================================================================================================\n|        metrics         |                       acc                        |                       auc                        |\n--------------------------------------------------------------------------------------------------------------------------------\n|                        |      mean      |      std       |     score      |      mean      |      std       |     score      |\n--------------------------------------------------------------------------------------------------------------------------------\n|          fcnn          |    0.980000    |    0.000000    |    0.980000    |    0.998867    |    0.000000    |    0.998867    |\n================================================================================================================================\n")),Object(i.b)("p",null,"You might notice that:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"The final results obtained by ",Object(i.b)("strong",{parentName:"li"},"HPO")," is even better than the stacking ensemble results mentioned above."),Object(i.b)("li",{parentName:"ul"},"We search for ",Object(i.b)("inlineCode",{parentName:"li"},"optimizer")," and ",Object(i.b)("inlineCode",{parentName:"li"},"lr")," as default. In fact, we can manually passed ",Object(i.b)("inlineCode",{parentName:"li"},"params")," into ",Object(i.b)("inlineCode",{parentName:"li"},"cflearn.tune_with"),". If not, then ",Object(i.b)("inlineCode",{parentName:"li"},"carefree-learn")," will execute following codes:")),Object(i.b)("pre",null,Object(i.b)("code",Object(a.a)({parentName:"pre"},{className:"language-python"}),'from cftool.ml.param_utils import *\n\nparams = {\n    "optimizer": String(Choice(values=["sgd", "rmsprop", "adam"])),\n    "optimizer_config": {\n        "lr": Float(Exponential(1e-5, 0.1))\n    }\n}\n')))}b.isMDXComponent=!0}}]);